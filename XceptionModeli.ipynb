{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOBYA0b2OGCTBGVHe3Mzbip"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jITygj-ozm7F"},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.applications import vgg16\n","from tensorflow.keras.applications import resnet50\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","\n","import numpy as np\n","import random\n","import math\n","import csv\n","import cv2\n","import os\n","\n","\"\"\"\n","Bu dosyada Xception hazır olan model kullanılacak.\n","\"\"\""]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","from sklearn.model_selection import train_test_split\n","from keras.utils.np_utils import to_categorical\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import mean_squared_error\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import MaxPool2D # üstteki MaxPooling2D ile aynı şey. ister onu ister bunu kullan.\n","#kodda ikisi de kullanıldığı için eklendi. yoksa biri ile yapılsaydı da olurdu.\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.optimizers.legacy import Adam\n","from tensorflow.keras.optimizers import SGD"],"metadata":{"id":"B1GhRo5rBiZE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputBasePath    = r\"/content/Project/Dataset\"\n","outputBasePath =  r\"/content/Project/DatasetArray\" #bu klasörlerin daha önce oluşturulmuş olması gerek\n","image_width = 299\n","image_height = 299\n","classes = ['2', '3', '4', '5']"],"metadata":{"id":"6lunwm6KlfwP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Bu kodda veri setinden ilgili katergorileri bütün fotoğraflarını okunup numpy dizisine atanıyor ve bir dosyda kaydediliyor. Sonradan farklı model\n","  denenmek istediğinde fotoğrafları baştan okumamamk için. iki tane npy dosyası oluşturuluyor biri \"images\" girdi olarak çıktı olarak da ilgili\n","  fotoğrafın ait olduğu kategori o da \"labels\" dosyasında kaydediliyor.\n","\n","\"\"\"\n","os.chdir(inputBasePath)\n","\n","X = []\n","Y = []\n","\n","for class1 in classes:\n","    os.chdir(class1)\n","    print('=> ' + class1)\n","\n","    for file in os.listdir('./'):\n","        if not file.lower().endswith(('.jpg', '.jpeg', '.png')):\n","            continue\n","\n","        img = cv2.imread(file)\n","        if img is None:\n","            print(f\"{file} adlı resim okunamadı.\")\n","            continue\n","\n","        img = cv2.resize(img, (image_width, image_height))\n","        img = vgg16.preprocess_input(img)\n","        X.append(img)\n","        Y.append(class1)\n","\n","    os.chdir('..')\n","\n","X = np.array(X).reshape(-1, image_width, image_height, 3)\n","Y = np.array(Y)\n","\n","os.chdir('..')\n","os.makedirs(\"DatasetArray\", exist_ok=True)\n","os.chdir(\"DatasetArray\")\n","\n","np.save(f\"{image_width}x{image_height}_images\", X)\n","np.save(f\"{image_width}x{image_height}_labels\", Y)\n","\n","print(\"[BİLGİ - AŞAMA 1] NUMPY DİZİSİ OLUŞTURMA TAMAMLANDI\\n\")"],"metadata":{"id":"VCKmkhbm0FPZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# npy diye kaydedilen x ve y değerleri okunup ilki data ikincisi labels değişkenine atanıyor.\n","data = np.load(r\"\" + outputBasePath +f\"/{image_width}x{image_height}_images.npy\")\n","labels = np.load(r\"\" + outputBasePath +f\"/{image_width}x{image_height}_labels.npy\")\n","data.shape"],"metadata":{"id":"UjoNZc-K0_rE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sınıflarımız \"2,3,4,5\" LabelEncode sınıfını kullanarak çıktı katmananında her birinin hangi neorunun bir geldiğinde ele alınacağını hesaplıyoruz\n","labelEn = LabelEncoder()\n","labels = labelEn.fit_transform(labels)\n","labels = to_categorical(labels)"],"metadata":{"id":"RsGyjsp61VjX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#veri array'e kaydedilmeden önce reshape edildiğinden array den okununca da düzgün gelir. yeniden reshape etmeye gerek yok\n","#eğer array'e atarken son değer 3 olarak yazılmasaydı burada reshape gerekirdi\n","\n","#data =  data.reshape(-1,image_width , image_height , 3)\n","\n","\n","\n","\n","# train -test split\n","#%10 test %80 eğitim seti olacak şekilde böl\n","x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size = .10, shuffle = True)\n","#shuffle görüntüleri karıştırmaya yarıyor\n","\n","\n","print(\n","\"\"\"\n","x_train shape: {}\n","x_test shape: {}\n","y_train shape: {}\n","y_test shape: {}\n","\n","\"\"\".format(x_train.shape, x_test.shape, y_train.shape, y_test.shape))"],"metadata":{"id":"VimpsCyj1ViZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Standart sapmayı ve ortalamayı kullanarak normalizasyon işlemi yapılıyor.\n","\n","x_train_mean = np.mean(x_train)\n","x_train_std = np.std(x_train)\n","\n","x_test_mean = np.mean(x_test)\n","x_test_std = np.std(x_test)\n","\n","x_train = (x_train - x_train_mean)/x_train_std\n","x_test = (x_test - x_test_mean)/x_test_std"],"metadata":{"id":"cCT7GhGT1Vhi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = .10, shuffle = True,random_state=42)\n","# random_state rastgele seçilen değerlerin bir sonraki aşamada aynı değerler ile devam edilmesini sağlar."],"metadata":{"id":"Tihph-UnwMjn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Kayıp Fonkisyonunu en aza indirmek için optimizer kullanılıyor.\n","optimizer = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"],"metadata":{"id":"8cZMeOG11VWy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epc = 30 # öğrenme iterasyon sayısı genelde en az 100 kere olması gerekiyor\n","bs = 8"],"metadata":{"id":"3lr6_gHUGm5N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Keras kütüphanesinde hazır olan Xception modelini kullanarak eğitme işlemi yapılacak.\n","import tensorflow as tf\n","\n","base_model = tf.keras.applications.Xception(\n","    include_top=True,\n","    weights=\"imagenet\",\n","    input_tensor=None,\n","    input_shape=None,\n","    pooling=None,\n","    classes=1000,\n","    classifier_activation=\"softmax\",\n",")"],"metadata":{"id":"89OK3nsLGndS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["NUM_CLASSES = len(classes)# kategorilerin sayısı alınıyor.\n","\n","\n","model = tf.keras.models.Sequential()\n","model.add(base_model)\n","model.add(Flatten()) # Matrisi bir vektöre dönüştürmek için Flatten işlemi uyguluyoruz.\n","model.add(Dropout(0.5)) # Overfitting aşırı uyumu önlemek için Dropout ekledik.\n","model.add(Dense(NUM_CLASSES, activation='softmax')) # sınıflandırma için sofmax fonksiyonunu kullandık.\n","\n","model.layers[0].trainable = False"],"metadata":{"id":"Ksdow1WqGnan"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"kmLO9yteGnYB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer = \"adam\" , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"],"metadata":{"id":"uPprxCAZHWOF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modelin öğrenme sırasında beli bir epoch saysında iyileştirme katetmezse devereye girer ve modelin baştan öğrenmesini başlatır.\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1,  factor=0.5, min_lr=0.00001)"],"metadata":{"id":"Rh6k27D9HWLg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modeli eğitmeye başlıyoruz.\n","history = model.fit(x_train,y_train, batch_size=bs,\n","                          epochs = epc, validation_data = (x_validate,y_validate),\n","                          verbose = 1, callbacks=[learning_rate_reduction])"],"metadata":{"id":"Bi0Yr7ZwHWJB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# modeli test verisi üzerinde çalıştırıp ilk on tahminin doğruluğuna bakıyorum.\n","model.evaluate(x_test, y_test)\n","ypred = model.predict(x_test)\n","ypred1 = [np.argmax(element) for element in ypred]\n","print(ypred1[:10])\n","print(y_test[:10])"],"metadata":{"id":"Y1zIaFSrJMY6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# yapılan tahminlerin kaçı kaçı yanlış sayan fonkisyon.\n","def count_the_Wrong_pred(ypred, y_test):\n","  trues = 0\n","  wrongs = 0\n","  for i in range(len(ypred)):\n","\n","    if y_test[i][int(ypred[i])] == 1.0:\n","      trues += 1\n","    else:\n","      wrongs += 1\n","\n","  return trues, wrongs"],"metadata":{"id":"KSWD4VTaJMWK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Yanlış ve doğru yapılan tahminleri yazdırıyorum.\n","trues, wrongs = count_the_Wrong_pred(ypred1, y_test)\n","print(\"trures:\" , trues)\n","print(\"wrongs:\" , wrongs)"],"metadata":{"id":"_wslzQ8WJMTl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Doğruluk oranını graphla çizidiriyoruz.\n","import matplotlib.pyplot as plt\n","\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"metadata":{"id":"Druygd6EJMRH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# yanlışlık oranların grafı.\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"metadata":{"id":"p3G-atzaJMO-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NGYm3QqXJMMw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DnXon5HRJMKX"},"execution_count":null,"outputs":[]}]}